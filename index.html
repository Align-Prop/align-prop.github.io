<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta charset="utf-8">
  <meta property="og:title" content="Align-Prop" />
  <meta property="og:description" content="We propose AlignProp, a method that uses reward backpropogation for the alignment of large-scale text-to-image diffusion models." />
  <meta property="og:url" content="https://align-prop.github.io/" />
  <meta property="og:image" content="https://align-prop.github.io/method.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="628" />

  <meta name="viewport" content="initial-scale=1" />
  <meta name="description" content="We propose AlignProp, a method that uses reward backpropogation for the alignment of large-scale text-to-image diffusion models.">
  <meta name="keywords" content="alignment, diffusion models, reinforcement learning, text-to-image models, direct reward learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- twitter -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="AlignProp" />
  <meta name="twitter:description"
      content="We propose AlignProp, a method that uses reward backpropogation for the alignment of large-scale text-to-image diffusion models." />
  <meta name="twitter:url" content="https://align-prop.github.io/" />
  <meta name="twitter:image" content="https://align-prop.github.io/method.png" />
  <meta name="twitter:site" content="@mihirp98" />
  <meta name="twitter:image" content="https://align-prop.github.io/method.png" />
  <meta name="twitter:image:src" content="https://align-prop.github.io/method.png" />
  <meta name="twitter:image_alt" content="align-prop" />

  <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NXF59J4');</script>
  <!-- End Google Tag Manager -->

  <title>Align-Prop</title>
  <link rel="stylesheet" href="./static/css//range_style_new.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet"href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://use.typekit.net/iag3ven.css">
  <link rel="stylesheet" href="./static/css/prism.css">

  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’«</text></svg>">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js">
  </script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js">
  </script>  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script> 


  
  
</head>

<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF59J4"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Aligning Text-to-Image Diffusion Models with Reward Backpropagation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mihirp1998.github.io/">Mihir Prabhudesai</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://anirudh9119.github.io/">Anirudh Goyal</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~dpathak/">Deepak Pathak</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Carnegie Mellon University,</span>
            <span class="author-block"><sup>2</sup>Google DeepMind</span>
          </div>
          <!-- <div class="is-size-5 pt-2 pb-2 has-text-centered publication-venue">
            <span>In Submission</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2310.03739.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.03739"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mihirp1998/AlignProp/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <!-- <div class="container is-max-desktop"> -->
    <div class="is-centered has-text-centered">
    <div class="hero-body ">

      <!-- Poster. -->
      <!-- <div class="columns mt-4"> -->

        <video   width="1200" autoplay muted>
          <source src="promo2.m4v" type="video/mp4">
          Your browser does not support the video tag.
      </video>

      <!-- </div>    -->
      

      <h2 class="pt-1 container is-max-desktop subtitle has-text-centered">
        AlignProp is a direct backpropagation-based approach to finetune text-to-image diffusion models for desired reward function. Above we show finetuning results for various reward functions. 
      </h2> 
    <!--/ Poster. -->
    </div>
  <!-- </div> -->
  </div>
</section>

<section class="section pt-2">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 p">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-image diffusion models have recently emerged at the forefront of image generation, powered by very large-scale unsupervised or weakly supervised text-to-image training datasets.  Due to the unsupervised   training,  controlling  their behavior in downstream tasks, such as maximizing human-perceived image quality,  image-text alignment, or ethical image generation, is difficult. Recent works finetune diffusion models to downstream reward functions using vanilla reinforcement learning, notorious for the high variance of the gradient estimators. In this paper, we propose AlignProp, a method that aligns diffusion models to downstream reward functions using end-to-end backpropagation of the reward gradient through the denoising process. While naive implementation of such backpropagation would require prohibitive memory resources for storing the partial derivatives of modern text-to-image models, AlignProp finetunes low-rank adapter weight modules and uses gradient checkpointing, to render its memory usage viable. We test AlignProp in finetuning diffusion models to various objectives, such as image-text semantic alignment, aesthetics, compressibility and controllability of the number of objects present, as well as their combinations.  We show AlignProp  achieves higher rewards in fewer training steps than alternatives, while being conceptually simpler, making it a straightforward choice for optimizing diffusion models for differentiable reward functions of interest. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/6LdBdg8IWug?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<!-- Method Overview -->
<section class=" is-light is-small" id="method-overview">
  <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
          <div class="column" style="border-radius: 10px; background-color: rgb(245,245,245)">
              <h2 class="title is-3">
                  <span class="method-name mt-3">AlignProp</span>
              </h2>
              <p style="padding: 10px;">
              </p><div id="method-overview-wrapper">
                  <img src="method.png" alt="AlignProp method." class="method-overview-full-img  method-overview" draggable="false" style="display: inline;">
              </div>
                      <p style="padding: 10px;">
                  </p><div class="method-overview-text has-text-justified">
                      <p>
                        <!-- <p class="has-text-weight-semibold">Model architecture for AlignProp. </p> -->
                        Given a batch of prompts, AlignProp generates images from noise through DDIM Sampling. The generated images are then evaluated using a Reward model to get a reward score. The optimization process involves updating the weights in the diffusion process by minimizing the negative of the obtained reward through gradient descent. To mitigate overfitting, we randomize the number of time-steps we backpropagate gradients to. 
                      </p>
                  </div>
              </div>
          </div>
      </div>
  
</section>
<!-- / Method Overview -->

<!-- Results Overview -->
<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">



        <!-- <h2 class="title is-3 has-text-centered">Disabling LoRA Weights</h2>
        <p>
          We illustrate the impact of deactivating finetuned LoRA weights across varying ranges of diffusion timesteps during inference. The visualization highlights that earlier timesteps predominantly contribute to semantic aspects, whereas the later timesteps are instrumental in capturing fine-grained details.
        </p>    
        <div class="column ml-4"> 
          <div  id="interpolation-ex7-wrapper">
            <img src="./lora_disable.png"
                 class="interpolation-image"
                 alt="Seg Acc Curve."/>       
          </div>                        
        </div>          -->
        <!-- <div class="columns mt-4">
          <div class="column"> 
            <div  id="interpolation-ex6-wrapper">
              <img src="./static/slot_tta_gifs/ex6.gif"
                   class="interpolation-image"
                   alt="Seg Acc Curve."/>       
            </div>
          </div>


      </div>    -->

        <h2 class="title pt-5 has-text-centered">Sample and Data Efficiency in Reward Finetuning</h2>
        <div  class="content has-text-justified">
          <p>
            <a href="https://arxiv.org/abs/2305.13301">DDPO</a> is the current state-of-the-art method for fine-tuning text-to-image models using reinforcement learning. 
            However it uses REINFORCE for finetuning the diffusion process. RL methods such as REINFORCE are notorious for their high variance in gradients and thus often result in poor sample efficiency.
            We on the other hand, do backpropogation and send gradients from the reward model to the diffusion process. This results in a significant boost in convergence speed and sample efficienncy.
            In the top half of the figure, we compare the data efficiency of AlignProp and DDPO across various reward models. In the bottom half of the figure we compare the convergence speed of AlignProp and DDPO. 
            As can be seen, AlignProp is about 25 times faster in training than DDPO. For instance on HPS v2 dataset scenario, AlignProp achieves a score of 2.8 in just 48 minutes, whereas DDPO requires approximately 23 hours.
            <div class="columns mt-4">
              <img src="./reward_tuning.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>   
    
          </div>   
        </div>

      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Generalization to new text prompts</h2>
        <p>
          An important benefit of finetuning the diffusion model, over prompt or initial noise finetuning , is generalization to new prompts. Here, we evaluate AlignProp and baselines, on their capacity for generalization.
          In the Figure above, we qualitatively compare the image generations on novel animals that were not encountered during the training phase. In this scenario, both AlignProp and the baselines are trained using an Aesthetic reward model.
        </p>    
        <div class="columns mt-4">

          <img src="animal_baselines_2.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>       

        </div>
      </div>
    </div>
</div>
</section> -->
    


<!-- <section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Human Preference V2</h2>
        <p>
          In this Figure we qualitatively compare AlignProp with Stable diffusion while using multiple prompts of HPS v2 evaluation prompt dataset. As can be seen AlignProp achieves higher fidelity results with better image-text alignment.
        </p>    
        <div class="columns mt-4">

          <img src="hps_results.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>       

        </div>
      </div>
    </div>
</div>
</section> -->


<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Interactive Mixing Results</h2>

        <p>
          In this context, we demonstrate the ability of AlignProp to interpolate between different reward functions during the inference phase. We draw inspiration from the concept presented in <a href="https://arxiv.org/abs/2203.05482">ModelSoup</a>, which showcases how averaging the weights of multiple fine-tuned models can enhance image classification accuracy.Expanding upon this idea, we extend it to the domain of image editing, revealing that averaging the LoRA weights of diffusion models trained with distinct reward functions can yield images that satisfy multiple reward criteria. AlignProp adeptly demonstrates its capacity to interpolate between distinct reward functions, achieving the highest overall reward when the mixing coefficient is set to 0.5. 
          <strong>Please move the slider to visualize results with different mixing coefficients.</strong>
        </p>    
 
      <div class="pt-4 columns mb-0 is-vcentered  has-text-centered">
          <div  class="column">
            <h2 class="is-size-5">Aesthetic Model</h2>
            <img src="./animals/spider/0.png"
                class="interpolation-image"
                alt="Seg Acc Curve."/>       
          </div>        
          <div  class="column" id="interpolation-ex3-wrapper">
            <h2 class="is-size-5">Hybrid Model</h2>
            <img src="./animals/spider/5.png"
                 class="interpolation-image"
                 alt="Seg Acc Curve."/>       
          </div>
          <div  class="column">
            <h2 class="is-size-5">Compression Model</h2>
            <img src="./animals/spider/10.png"
                 class="interpolation-image"
                 alt="Seg Acc Curve."/>       
          </div>          
      </div>

      <div class="pt-0 columns mb-0 is-vcentered  has-text-centered">
        <div  class="column">
          <h2 class="is-size-5">Aesthetic Model</h2>
          <img src="./animals/sheep/0.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>       
        </div>        
        <div  class="column" id="interpolation-ex4-wrapper">
          <h2 class="is-size-5">Hybrid Model</h2>
          <img src="./animals/sheep/5.png"
               class="interpolation-image"
               alt="Seg Acc Curve."/>       
        </div>
        <div  class="column">
          <h2 class="is-size-5">Compression Model</h2>
          <img src="./animals/sheep/10.png"
               class="interpolation-image"
               alt="Seg Acc Curve."/>       
        </div>          
    </div>

      <!-- <section class="all-sliders"> -->
        <!-- <label>
          <input class="slider" id="range-slider" type="range" min="1" step="0.01" max="100" value="80">
        </label> -->
      <!-- </section>       -->
      <div class="columns pt-5">
        <div class="column is-half is-offset-one-quarter">
      
      <div class="columns  is-vcentered">

        <div class="column is-11 pr-0 pl-0 ml-0 mr-0 has-text-centered" id="slider-container">
          <!-- <label>
          <input class="slider" id="range-slider-poster" type="range" min="1" step="1" max="265" value="0">          
        </label> -->
        <input class="is-fullwidth is-large is-info" id="range-slider-poster" name="slider" type="range" value=5>
              
          <!-- <input class="slider is-fullwidth is-large is-info"
                 id="interpolation-slider"
                 step="1" min="0" max="265" value="0" type="range">     -->
        </div>        
        <div class="column pr-0 pl-0 ml-0 mr-0">
          <label for="slider">0.5</label>

        </div>
        
      </div>
    </div>
  </div>

      <h2 class="subtitle has-text-centered">
        Hybrid Model - Mixing Coefficient (&alpha;)
      </h2>


      </div>
    </div>
</div>
</section>


<!-- / Results Overview -->

<section class="section" id="paper">
  <div class="container is-mobile">
      <div class="columns is-centered has-text-centered">
          <div class="container content">
              <h2 class="title is-3">BibTeX</h2>
              <div id="bibtex" class="column has-text-justified is-centered">
                  <!-- https://github.com/SaswatPadhi/prismjs-bibtex -->
                  <pre class="language-bibtex"><code class=" language-bibtex"><span class="token class-name">@misc</span><span class="token punctuation">{</span><span class="token key regex">prabhudesai2023aligning</span><span class="token punctuation">,</span>
              <span class="token property">title</span><span class="token string">={Aligning Text-to-Image Diffusion Models with Reward Backpropagation}</span><span class="token punctuation">,</span> 
              <span class="token property">author</span><span class="token string">={Mihir Prabhudesai and Anirudh Goyal and Deepak Pathak and Katerina Fragkiadaki}</span><span class="token punctuation">,</span>
              <span class="token property">year</span><span class="token string">={2023}</span><span class="token punctuation">,</span>
              <span class="token property">eprint</span><span class="token string">={2310.03739}</span><span class="token punctuation">,</span>
              <span class="token property">archivePrefix</span><span class="token string">={arXiv}</span><span class="token punctuation">,</span>
              <span class="token property">primaryClass</span><span class="token string">={cs.CV}</span>
              <span class="token punctuation">}</span></code><button>copy</button></pre>
              </div>
          </div>
      </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2310.03739.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/align-prop/align-prop.github.io" class="external-link" disabled>
        <i class="fab fa-github"></i>
      <div class="column is-8">

      </div>
    </div>
  </div>
</footer>

<script src="./static/js/index.js"></script>
<!-- <script src="./static/js/prism.js"></script> -->
<script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.js"
    integrity="sha256-+dK6uqUp/DnP6ef97s8XcoynBnGe5vM5gvBECH0EB3U=" crossorigin="anonymous">
    </script>
</body>
</html>
