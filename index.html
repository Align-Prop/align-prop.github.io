<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta charset="utf-8">
  <meta property="og:title" content="Slot-TTA" />
  <meta property="og:description" content="We propose Slot-TTA, a  semi-supervised slot-centric scene decomposition model that at test time is adapted per scene  through gradient descent on reconstruction or cross-view synthesis objectives." />
  <meta property="og:url" content="https://slot-tta.github.io/" />
  <meta property="og:image" content="https://slot-tta.github.io/static/images/preview.jpeg" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="628" />

  <meta name="viewport" content="initial-scale=1" />
  <meta name="description" content="We propose Slot-TTA, a semi-supervised slot-centric scene decomposition model that at test time is adapted per scene  through gradient descent on reconstruction or cross-view synthesis objectives.">
  <meta name="keywords" content="object-centric learning, test-time adaptation, entity-centric models, scene decomposition, Slot-TTA, GFS-Nets">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- twitter -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Slot-TTA" />
  <meta name="twitter:description"
      content="Slot-TTA, a semi-supervised slot-centric scene decomposition model that at test time is adapted per scene through gradient descent on reconstruction or cross-view synthesis objectives." />
  <meta name="twitter:url" content="https://slot-tta.github.io/" />
  <meta name="twitter:image" content="https://slot-tta.github.io/static/images/preview.jpeg" />
  <meta name="twitter:site" content="@mihirp98" />
  <meta name="twitter:image" content="https://slot-tta.github.io/static/images/preview.jpeg" />
  <meta name="twitter:image:src" content="https://slot-tta.github.io/static/images/preview.jpeg" />
  <meta name="twitter:image_alt" content="Slot-TTA" />

  <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NXF59J4');</script>
  <!-- End Google Tag Manager -->

  <title>Align-Prop</title>
  <link rel="stylesheet" href="./static/css//range_style_new.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet"href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://use.typekit.net/iag3ven.css">
  <link rel="stylesheet" href="./static/css/prism.css">

  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’«</text></svg>">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js">
  </script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.min.js">
  </script>  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script> 


  
  
</head>

<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NXF59J4"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
  


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Aligning Text-to-Image Diffusion Models with Reward Backpropagation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mihirp1998.github.io/">Mihir Prabhudesai</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://anirudh9119.github.io/">Anirudh Goyal</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~dpathak/">Deepak Pathak</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~katef/">Katerina Fragkiadaki</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Carnegie Mellon University,</span>
            <span class="author-block"><sup>2</sup>Google DeepMind</span>
          </div>
          <!-- <div class="is-size-5 pt-2 pb-2 has-text-centered publication-venue">
            <span>In Submission</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2310.03739.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.03739"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mihirp1998/AlignProp/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <div class="hero-body column is-four-fifths">

      <!-- Poster. -->
      <div class="columns mt-4">

            <img src="teaser.png"
                 class="interpolation-image"
                 alt="Seg Acc Curve."/>       


      </div>   
      

      <h2 class="subtitle has-text-centered">
        We present a direct backpropagation-based approach to adapt text-to-image diffusion models for desired reward function. The above examples showcase the adaptation of diffusion model output (epoch 0) through a sequence of adaptation steps (epoch 1-10) to different reward functions. The reward function in the left two examples is that of concept removal trained to disregard the concept of "books," despite the prompt explicitly mentioning "fruits and books." The reward function for the adaptation on the right is that of human-preference alignment crafted from human rankings of image-text pairs. As shown in all the examples, the proposed approach can effectively align the diffusion model with the reward function
      </h2>
    <!--/ Poster. -->
    </div>
  </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-to-image diffusion models have recently emerged at the forefront of image generation, powered by very large-scale unsupervised or weakly supervised text-to-image training datasets.  Due to the weakly supervised   training,  controlling  their behavior in downstream tasks, such as maximizing human-perceived image quality,  image-text alignment, or ethical image generation, is difficult. Recent works finetune diffusion models to downstream reward functions using vanilla reinforcement learning, notorious for the high variance of the gradient estimators. In this paper, we propose AlignProp, a method that aligns diffusion models to downstream reward functions using end-to-end backpropagation of the reward gradient through the denoising process. While naive implementation of such backpropagation would require prohibitive memory resources for storing the partial derivatives of modern text-to-image models, AlignProp finetunes low-rank adapter weight modules and uses gradient checkpointing, to render its memory usage viable. We test AlignProp in finetuning diffusion models to various objectives, such as image-text semantic alignment, aesthetics, compressibility and controllability of the number of objects present, as well as their combinations.  We show AlignProp  achieves higher rewards in fewer training steps than alternatives, while being conceptually simpler, making it a straightforward choice for optimizing diffusion models for differentiable reward functions of interest. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/6LdBdg8IWug?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<!-- Method Overview -->
<section class=" is-light is-small" id="method-overview">
  <div class="container is-max-widescreen">
      <div class="columns is-centered has-text-centered">
          <div class="column" style="border-radius: 10px; background-color: rgb(245,245,245)">
              <h2 class="title is-3">
                  <span class="method-name mt-3">Align-Prop</span>
              </h2>
              <p style="padding: 10px;">
              </p><div id="method-overview-wrapper">
                  <img src="method.png" alt="Slot TTA method." class="method-overview-full-img  method-overview" draggable="false" style="display: inline;">
              </div>
                      <p style="padding: 10px;">
                  </p><div class="method-overview-text has-text-justified">
                      <p>
                        <p class="has-text-weight-semibold">Model architecture for Align-Prop. <strong >(top)</strong> and 3D point clouds <strong >(bottom)</strong>. </p>
                        When presented with a batch of prompts, Align-Prop initiates the generation of images from noise through DDIM Sampling. Subsequently, these generated images undergo evaluation by the Reward model to acquire a corresponding reward score. The optimization process involves updating the weights in the diffusion process by minimizing the negative of the obtained reward through gradient descent. To mitigate overfitting, we randomize the number of time-steps we backpropagate gradients to. 
                      </p>
                  </div>
              </div>
          </div>
      </div>
  
</section>
<!-- / Method Overview -->

<!-- Results Overview -->
<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">



        <h2 class="title is-3 has-text-centered">Disabling LoRA Weights</h2>
        <p>
          We illustrate the impact of deactivating finetuned LoRA weights across varying ranges of diffusion timesteps during inference. The visualization highlights that earlier timesteps predominantly contribute to semantic aspects, whereas the later timesteps are instrumental in capturing fine-grained details.
        </p>    
        <div class="column ml-4"> 
          <div  id="interpolation-ex7-wrapper">
            <img src="./lora_disable.png"
                 class="interpolation-image"
                 alt="Seg Acc Curve."/>       
          </div>                        
        </div>         
        <!-- <div class="columns mt-4">
          <div class="column"> 
            <div  id="interpolation-ex6-wrapper">
              <img src="./static/slot_tta_gifs/ex6.gif"
                   class="interpolation-image"
                   alt="Seg Acc Curve."/>       
            </div>
          </div>


      </div>    -->

        <h2 class="title pt-5 has-text-centered">Sample and Data Efficiency in Reward Finetuning</h2>
        <div  class="content has-text-justified">
          <p>
            Reward finetuning results  on multiple reward functions. In the top half of the figure, we compare the data efficiency of Align-Prop and DDPO. In the bottom half of the figure we compare the convergence speed of Align-Prop and DDPO. As seen Align-Prop outperforms DDPO on both metrics.
            <div class="columns mt-4">
              <img src="./reward_tuning.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>   
    
          </div>   
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Generalization to new text prompts</h2>
        <p>
          Qualitative comparison with baselines is conducted on novel animals that were not encountered during the training phase. In this scenario, both Align-Prop and the baselines are trained using an Aesthetic reward model.
        </p>    
        <div class="columns mt-4">

          <img src="animal_baselines_2.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>       

        </div>
      </div>
    </div>
</div>
</section>
    


<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Human Preference V2</h2>
        <p>
          In this Figure we qualitatively compare Align-Prop with Stable diffusion while using multiple prompts of HPS v2 evaluation prompt dataset. As can be seen Align-Prop achieves higher fidelity results with better image-text alignment.
        </p>    
        <div class="columns mt-4">

          <img src="hps_results.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>       

        </div>
      </div>
    </div>
</div>
</section>




<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Mixing Results</h2>
        <p>
          In this Figure we show additional mixing results between compressibilty and Aesthetic model. 
        </p>    
        <div class="columns mt-4">

          <img src="mixing_full.png"
              class="interpolation-image"
              alt="Seg Acc Curve."/>       

        </div>
      </div>
    </div>
</div>
</section>


<!-- / Results Overview -->

<section class="section" id="paper">
  <div class="container is-mobile">
      <div class="columns is-centered has-text-centered">
          <div class="container content">
              <h2 class="title is-3">BibTeX</h2>
              <div id="bibtex" class="column has-text-justified is-centered">
                  <!-- https://github.com/SaswatPadhi/prismjs-bibtex -->
                  <pre class="language-bibtex"><code class=" language-bibtex"><span class="token class-name">@misc</span><span class="token punctuation">{</span><span class="token key regex">prabhudesai2023aligning</span><span class="token punctuation">,</span>
              <span class="token property">title</span><span class="token string">={Aligning Text-to-Image Diffusion Models with Reward Backpropagation}</span><span class="token punctuation">,</span> 
              <span class="token property">author</span><span class="token string">={Mihir Prabhudesai and Anirudh Goyal and Deepak Pathak and Katerina Fragkiadaki}</span><span class="token punctuation">,</span>
              <span class="token property">year</span><span class="token string">={2023}</span><span class="token punctuation">,</span>
              <span class="token property">eprint</span><span class="token string">={2310.03739}</span><span class="token punctuation">,</span>
              <span class="token property">archivePrefix</span><span class="token string">={arXiv}</span><span class="token punctuation">,</span>
              <span class="token property">primaryClass</span><span class="token string">={cs.CV}</span>
              <span class="token punctuation">}</span></code><button>copy</button></pre>
              </div>
          </div>
      </div>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2203.11194">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/mihirp1998/Slot-TTA.git" class="external-link" disabled>
        <i class="fab fa-github"></i>
      <div class="column is-8">

      </div>
    </div>
  </div>
</footer>

<script src="./static/js/index.js"></script>
<script src="./static/js/prism.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.0.1/prism-bibtex.js"
    integrity="sha256-+dK6uqUp/DnP6ef97s8XcoynBnGe5vM5gvBECH0EB3U=" crossorigin="anonymous">
    </script>
</body>
</html>
